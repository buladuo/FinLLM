# 全局配置
global:
  default_model: "gpt-4o-mini"  # 默认使用的模型名称
  sql_reason_model: "gpt-4o-mini"
  entity_recognition_agent_model: "gpt-4o-mini"
  default_embedding: "silicon-bge-m3"  # 默认使用的词向量模型名称
  embedding_pool_size: 5       # 词向量模型的缓冲池大小

  request_timeout: 720          # 请求超时时间（秒）
  retries: 3                   # 失败时的重试次数
  top_k: 5                     # 返回前k个最相似的问题

# 模型后端配置
models:
  gpt-4o-mini:
    name: "gpt-4o-mini"          
    api_base: "https://free.v36.cm/v1" 
    api_key: "sk-xxx"      # 模型后端的 API 密钥
    model_type: chat
    type: openai
    rpm: 96

  gpt-3.5-turbo-0125:
    name: "gpt-3.5-turbo-0125"          
    api_base: "https://free.v36.cm/v1" 
    api_key: "sk-xxx"      # 模型后端的 API 密钥
    model_type: chat
    type: openai
    rpm: 96

  gpt-3.5-turbo-1106:
    name: "gpt-3.5-turbo-1106"          
    api_base: "https://free.v36.cm/v1" 
    api_key: "sk-xxx"      # 模型后端的 API 密钥
    model_type: chat
    type: openai
    rpm: 96

  gpt-3.5-turbo:
    name: "gpt-3.5-turbo"          
    api_base: "https://free.v36.cm/v1" 
    api_key: "sk-xxx"      # 模型后端的 API 密钥
    model_type: chat
    type: openai
    rpm: 96

  gpt-3.5-turbo-16k:
    name: "gpt-3.5-turbo-16k"          
    api_base: "https://free.v36.cm/v1" 
    api_key: "sk-xxx"      # 模型后端的 API 密钥
    model_type: chat
    type: openai
    rpm: 96

  qwen:
    name: "qwen"          
    api_base: "http://127.0.0.1:8011/v1" 
    api_key: "xxx"      # 模型后端的 API 密钥
    model_type: chat
    type: openai
    rpm: 5
  
  qwen-7b:
    name: "Qwen/Qwen2-7B-Instruct"          
    api_base: "https://api.siliconflow.cn/v1"
    api_key: "sk-xxx"  
    model_type: chat
    type: openai
    rpm: 100

  glm-4:
    name: "glm-4"          
    api_base: "https://open.bigmodel.cn/api/paas/v4"  
    api_key: "xxx"    # 模型后端的 API 密钥
    model_type: chat
    type: openai
    rpm: 100


  glm-4-plus:
    name: "glm-4-plus"         
    api_base: "https://open.bigmodel.cn/api/paas/v4"  
    api_key: "xxx"    # 模型后端的 API 密钥
    model_type: chat
    type: openai
    rpm: 100


  glm-4-flash:
    name: "glm-4-flash"         
    api_base: "https://open.bigmodel.cn/api/paas/v4"  
    api_key: "xxx"    # 模型后端的 API 密钥
    model_type: chat
    type: openai
    rpm: 100

  glm-4-flashx:
    name: "glm-4-flashx"         
    api_base: "https://open.bigmodel.cn/api/paas/v4"  
    api_key: "xxx"    # 模型后端的 API 密钥
    model_type: chat
    type: openai
    rpm: 100

  glm-zero-preview:
    name: "glm-zero-preview"          
    api_base: "https://open.bigmodel.cn/api/paas/v4"  
    api_key: "xxx"    # 模型后端的 API 密钥
    model_type: think
    type: openai
    rpm: 100


  doubao:
    name: "doubao"            
    api_base: "http://127.0.0.1:8013/v1"  
    api_key: "xxx"    
    model_type: chat
    type: openai
    rpm: 5
  
  deepseek-chat:
    name: "deepseek-chat"
    api_base: "https://api.deepseek.com/v1"  
    api_key: "sk-xxx"  
    model_type: chat
    type: openai
    rpm: 256

  tianyi-deepseek-v3:
    name: "9dc913a037774fc0b248376905c85da5"
    api_base: "https://wishub-x1.ctyun.cn/v1"  
    api_key: "xxx"  
    model_type: chat
    type: openai
    rpm: 256

  silicon-deepseek:
    name: "deepseek-ai/DeepSeek-V3"
    api_base: "https://api.siliconflow.cn/v1"
    api_key: "sk-xxx"  
    model_type: chat
    type: openai
    rpm: 100
  deepseek-r1:
    name: "deepseek-r1"
    api_base: "http://127.0.0.1:8015/v1"  
    api_key: "xxx"   
    model_type: think
    type: openai
    rpm: 5
  deepseek-v3:
    name: "deepseek-v3"
    api_base: "http://127.0.0.1:8015/v1"  
    api_key: "xxx"   
    model_type: chat
    type: openai
    rpm: 5

embeddings:
  silicon-bge-m3:
    name: BAAI/bge-m3
    api_base: "https://api.siliconflow.cn/v1"
    api_key: "sk-xxx"
    model_type: embedding
    dim: 1024
    rpm: 2000
    tpm: 50000
  
  bce-embedding-base_v1:
    name: netease-youdao/bce-embedding-base_v1
    api_base: "https://api.siliconflow.cn/v1"
    api_key: "sk-xxx"
    model_type: embedding
    dim: 768
    rpm: 2000
    tpm: 50000
  
  glm-embedding-3:
    name: embedding-3
    api_base: "https://open.bigmodel.cn/api/paas/v4"
    api_key: "xxx.xxx"
    model_type: embedding
    dim: 2048
    dimensions: [2048,1024,512,256]
    rpm: 2000
    tpm: 50000
  

database:
  api_url: "https://comm.chatglm.cn/finglm2/api/query"  
  api_key: "xxx"             
  timeout: 15                                  

logging:
  level: "INFO"        # 日志级别，可选值：DEBUG, INFO, WARNING, ERROR
  # level: "DEBUG"        # 日志级别，可选值：DEBUG, INFO, WARNING, ERROR
  file_path: "./logs/"  
